{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9de7052b8b84fcdab6be063c245f1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_152f6b17dd0b4be687f5fa6fdb7abd06",
              "IPY_MODEL_a7a7baeb0a4f40e8a464ea534e398359",
              "IPY_MODEL_d6a571ac5ce44e61a14371675fe37106"
            ],
            "layout": "IPY_MODEL_95d02aededd44480877199d890a21c05"
          }
        },
        "152f6b17dd0b4be687f5fa6fdb7abd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61aa7f07c54f4a2eabebb277d32b079c",
            "placeholder": "​",
            "style": "IPY_MODEL_bda8cefde8b746efabfbd0d2d048acdf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a7a7baeb0a4f40e8a464ea534e398359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e0c6c20985043bdaa7e0d806696fc38",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b4ca07ea59b44a28e22e7b0d00fe086",
            "value": 2
          }
        },
        "d6a571ac5ce44e61a14371675fe37106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdd16dcaa9db4cab9029c7b575132692",
            "placeholder": "​",
            "style": "IPY_MODEL_c8799778d81d4c7688f0ce1223aa7c9f",
            "value": " 2/2 [00:02&lt;00:00,  1.05s/it]"
          }
        },
        "95d02aededd44480877199d890a21c05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61aa7f07c54f4a2eabebb277d32b079c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda8cefde8b746efabfbd0d2d048acdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e0c6c20985043bdaa7e0d806696fc38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4ca07ea59b44a28e22e7b0d00fe086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdd16dcaa9db4cab9029c7b575132692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8799778d81d4c7688f0ce1223aa7c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UrAnrlqqH-S",
        "outputId": "ece4065b-02e4-4c5e-9b6c-8ce3c0fd66ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 25 05:05:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0             67W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.33.0 torchmetrics\n",
        "!pip install git+https://github.com/haotian-liu/LLaVA.git@v1.6\n",
        "!pip install git+https://github.com/salesforce/LAVIS.git\n",
        "\n",
        "import os, json, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
        "from torchmetrics.classification import Accuracy\n",
        "from difflib import SequenceMatcher\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzrFZYhE4RHB",
        "outputId": "d143acd8-39a0-47bf-a11b-ff6df1f73297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.33.0 in /usr/local/lib/python3.11/dist-packages (4.33.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Collecting git+https://github.com/haotian-liu/LLaVA.git@v1.6\n",
            "  Cloning https://github.com/haotian-liu/LLaVA.git (to revision v1.6) to /tmp/pip-req-build-toi6x0wo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/haotian-liu/LLaVA.git /tmp/pip-req-build-toi6x0wo\n",
            "\u001b[33m  WARNING: Did not find branch or tag 'v1.6', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q v1.6\n",
            "  error: pathspec 'v1.6' did not match any file(s) known to git\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mgit checkout -q v1.\u001b[0m\u001b[1;32m6\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mgit checkout -q v1.\u001b[0m\u001b[1;32m6\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting git+https://github.com/salesforce/LAVIS.git\n",
            "  Cloning https://github.com/salesforce/LAVIS.git to /tmp/pip-req-build-6d0at52v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salesforce/LAVIS.git /tmp/pip-req-build-6d0at52v\n",
            "  Resolved https://github.com/salesforce/LAVIS.git to commit 506965b9c4a18c1e565bd32acaccabe0198433f7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting contexttimer (from salesforce-lavis==1.0.1)\n",
            "  Using cached contexttimer-0.3.3.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord (from salesforce-lavis==1.0.1)\n",
            "  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Collecting diffusers<=0.16.0 (from salesforce-lavis==1.0.1)\n",
            "  Using cached diffusers-0.16.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.8.1)\n",
            "Collecting fairscale==0.4.4 (from salesforce-lavis==1.0.1)\n",
            "  Using cached fairscale-0.4.4.tar.gz (235 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from salesforce-lavis==1.0.1)\n",
            "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting iopath (from salesforce-lavis==1.0.1)\n",
            "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (7.34.0)\n",
            "Collecting omegaconf (from salesforce-lavis==1.0.1)\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opencv-python-headless==4.5.5.64 (from salesforce-lavis==1.0.1)\n",
            "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting opendatasets (from salesforce-lavis==1.0.1)\n",
            "  Using cached opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (5.24.1)\n",
            "Collecting pre-commit (from salesforce-lavis==1.0.1)\n",
            "  Using cached pre_commit-4.1.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pycocoevalcap (from salesforce-lavis==1.0.1)\n",
            "  Using cached pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (2.0.8)\n",
            "Collecting python-magic (from salesforce-lavis==1.0.1)\n",
            "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.25.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.2.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (3.7.5)\n",
            "Collecting streamlit (from salesforce-lavis==1.0.1)\n",
            "  Using cached streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting timm==0.4.12 (from salesforce-lavis==1.0.1)\n",
            "  Using cached timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (4.67.1)\n",
            "Collecting transformers==4.33.2 (from salesforce-lavis==1.0.1)\n",
            "  Using cached transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n",
            "Collecting webdataset (from salesforce-lavis==1.0.1)\n",
            "  Using cached webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.45.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (2.5.1+cu124)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.13.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (1.0.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (3.9.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from salesforce-lavis==1.0.1) (0.14.0)\n",
            "Collecting easydict==1.9 (from salesforce-lavis==1.0.1)\n",
            "  Using cached easydict-1.9.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml_env_tag==0.1 (from salesforce-lavis==1.0.1)\n",
            "  Using cached pyyaml_env_tag-0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "INFO: pip is looking at multiple versions of salesforce-lavis to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement open3d==0.13.0 (from salesforce-lavis) (from versions: 0.18.0, 0.19.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for open3d==0.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_DIR = \"/content/drive/MyDrive/mmml_project_michelle/mmml_project\"\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "mini_gqa_path = \"mini_gqa.json\"\n",
        "with open(mini_gqa_path, 'r') as f:\n",
        "    mini_gqa_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(mini_gqa_data)} samples from mini_gqa.json.\")\n",
        "print(\"Example sample:\", mini_gqa_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B52f_cvQ8dB6",
        "outputId": "7d090b8a-d243-49c4-c4d1-ea0d6c13fac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 12578 samples from mini_gqa.json.\n",
            "Example sample: {'imageId': 'n161313', 'image_file': '/content/drive/MyDrive/mmml_project/gqa_images/n161313.png', 'question': 'Is it overcast?', 'answer': 'no', 'fullAnswer': 'No, it is clear.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "old_prefix = \"/content/drive/MyDrive/mmml_project/gqa_images/\"\n",
        "new_prefix = os.path.join(PROJECT_DIR, \"gqa_images\") + \"/\"\n",
        "for sample in mini_gqa_data:\n",
        "    if sample.get(\"image_file\", \"\").startswith(old_prefix):\n",
        "        sample[\"image_file\"] = sample[\"image_file\"].replace(old_prefix, new_prefix)\n",
        "print(\"Updated sample record:\", mini_gqa_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF2bDYiQNpCO",
        "outputId": "46cc9584-8f63-4d36-da3f-0d17b82fdb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated sample record: {'imageId': 'n161313', 'image_file': '/content/drive/MyDrive/mmml_project_michelle/mmml_project/gqa_images/n161313.png', 'question': 'Is it overcast?', 'answer': 'no', 'fullAnswer': 'No, it is clear.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "def similarity(a: str, b: str) -> float:\n",
        "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
        "\n",
        "def is_correct(prediction: str, gold: str, threshold=0.8) -> bool:\n",
        "    return similarity(prediction, gold) >= threshold\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DatigKRZBQTC",
        "outputId": "cb560e19-7bbb-4c19-cd85-941b02bad9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
        "\n",
        "processor_weak = AutoProcessor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\", use_fast=False)\n",
        "model_weak = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\").to(device)\n",
        "\n",
        "weak_predictions_list = []\n",
        "\n",
        "save_interval = 500\n",
        "start_time = time.time()\n",
        "\n",
        "total_samples = len(mini_gqa_data)\n",
        "for i, sample in enumerate(mini_gqa_data):\n",
        "    qid = sample[\"imageId\"]\n",
        "    img_path = sample[\"image_file\"]\n",
        "    question = sample[\"question\"]\n",
        "\n",
        "    try:\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening {img_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    inputs = processor_weak(image, question, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model_weak.generate(**inputs, max_new_tokens=20)\n",
        "    pred_answer = processor_weak.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    entry = {\n",
        "        \"imageId\": sample[\"imageId\"],\n",
        "        \"image_file\": sample[\"image_file\"],\n",
        "        \"question\": sample[\"question\"],\n",
        "        \"answer\": sample[\"answer\"],\n",
        "        \"fullAnswer\": sample.get(\"fullAnswer\", \"\"),\n",
        "        \"blip_response\": pred_answer\n",
        "    }\n",
        "\n",
        "    weak_predictions_list.append(entry)\n",
        "\n",
        "    if (i + 1) % save_interval == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Processed {i+1}/{total_samples} samples. Time elapsed: {elapsed/60:.2f} minutes.\")\n",
        "        temp_path = os.path.join(PROJECT_DIR, \"mini_gqa_with_weakB_fulljson_checkpoint.json\")\n",
        "        with open(temp_path, \"w\") as f:\n",
        "            json.dump(weak_predictions_list, f, indent=2)\n",
        "\n",
        "weak_out_path = os.path.join(PROJECT_DIR, \"mini_gqa_with_weakB_fulljson.json\")\n",
        "with open(weak_out_path, \"w\") as f:\n",
        "    json.dump(weak_predictions_list, f, indent=2)\n",
        "\n",
        "print(f\"WeakB predictions saved to: {weak_out_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "f9de7052b8b84fcdab6be063c245f1fc",
            "152f6b17dd0b4be687f5fa6fdb7abd06",
            "a7a7baeb0a4f40e8a464ea534e398359",
            "d6a571ac5ce44e61a14371675fe37106",
            "95d02aededd44480877199d890a21c05",
            "61aa7f07c54f4a2eabebb277d32b079c",
            "bda8cefde8b746efabfbd0d2d048acdf",
            "5e0c6c20985043bdaa7e0d806696fc38",
            "0b4ca07ea59b44a28e22e7b0d00fe086",
            "bdd16dcaa9db4cab9029c7b575132692",
            "c8799778d81d4c7688f0ce1223aa7c9f"
          ]
        },
        "id": "Od7UGgnHBfIe",
        "outputId": "faf7e749-5f67-429e-d1eb-b783f2dbe323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9de7052b8b84fcdab6be063c245f1fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 500/12578 samples. Time elapsed: 1.68 minutes.\n",
            "Processed 1000/12578 samples. Time elapsed: 3.35 minutes.\n",
            "Processed 1500/12578 samples. Time elapsed: 5.05 minutes.\n",
            "Processed 2000/12578 samples. Time elapsed: 6.73 minutes.\n",
            "Processed 2500/12578 samples. Time elapsed: 8.44 minutes.\n",
            "Processed 3000/12578 samples. Time elapsed: 10.13 minutes.\n",
            "Processed 3500/12578 samples. Time elapsed: 11.86 minutes.\n",
            "Processed 4000/12578 samples. Time elapsed: 13.53 minutes.\n",
            "Processed 4500/12578 samples. Time elapsed: 15.22 minutes.\n",
            "Processed 5000/12578 samples. Time elapsed: 16.94 minutes.\n",
            "Processed 5500/12578 samples. Time elapsed: 18.64 minutes.\n",
            "Processed 6000/12578 samples. Time elapsed: 20.31 minutes.\n",
            "Processed 6500/12578 samples. Time elapsed: 22.01 minutes.\n",
            "Processed 7000/12578 samples. Time elapsed: 23.70 minutes.\n",
            "Processed 7500/12578 samples. Time elapsed: 25.42 minutes.\n",
            "Processed 8000/12578 samples. Time elapsed: 27.14 minutes.\n",
            "Processed 8500/12578 samples. Time elapsed: 28.82 minutes.\n",
            "Processed 9000/12578 samples. Time elapsed: 30.50 minutes.\n",
            "Processed 9500/12578 samples. Time elapsed: 32.16 minutes.\n",
            "Processed 10000/12578 samples. Time elapsed: 33.86 minutes.\n",
            "Processed 10500/12578 samples. Time elapsed: 35.56 minutes.\n",
            "Processed 11000/12578 samples. Time elapsed: 37.21 minutes.\n",
            "Processed 11500/12578 samples. Time elapsed: 38.86 minutes.\n",
            "Processed 12000/12578 samples. Time elapsed: 40.56 minutes.\n",
            "Processed 12500/12578 samples. Time elapsed: 42.28 minutes.\n",
            "WeakB predictions saved to: /content/drive/MyDrive/mmml_project_michelle/mmml_project/mini_gqa_with_weakB_fulljson.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6w-XvELGBwsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}