{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDhlDJSmqvJ5",
        "outputId": "5fd37332-1693-4d14-da56-498b0550c71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/mmml_project/outputs\"\n",
        "\n",
        "file_paths = {\n",
        "    \"llava\": os.path.join(dataset_folder, \"mini_gqa_with_llava.json\"),\n",
        "    \"gpt\": os.path.join(dataset_folder, \"mini_gqa_with_gpt.json\"),\n",
        "    \"smolvlm\": os.path.join(dataset_folder, \"mini_gqa_with_smolvlm.json\"),\n",
        "    \"blip\": os.path.join(dataset_folder, \"mini_gqa_with_blip.json\"),\n",
        "}\n",
        "\n",
        "datasets = {}\n",
        "for model, path in file_paths.items():\n",
        "    with open(path, \"r\") as f:\n",
        "        datasets[model] = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_llava_response(response):\n",
        "    cleaned_response = re.sub(r\"\\[INST\\].*?\\n?.*?\\[/INST\\]\", \"\", response, flags=re.DOTALL).strip()\n",
        "    return cleaned_response\n",
        "\n",
        "for record in datasets[\"llava\"]:\n",
        "    record[\"llava_response\"] = clean_llava_response(record.get(\"llava_response\", \"\"))\n",
        "\n",
        "llava_cleaned_path = os.path.join(dataset_folder, \"mini_gqa_with_llava_cleaned.json\")\n",
        "with open(llava_cleaned_path, \"w\") as f:\n",
        "    json.dump(datasets[\"llava\"], f, indent=2)\n",
        "\n",
        "print(f\"Cleaned LLaVA dataset saved to: {llava_cleaned_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nkx3GZXOAVz",
        "outputId": "07532b23-cc22-4399-e9e5-14265b94e636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned LLaVA dataset saved to: /content/drive/MyDrive/mmml_project/outputs/mini_gqa_with_llava_cleaned.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_smolvlm_response(response, question):\n",
        "    response_cleaned = response.strip()\n",
        "    question_cleaned = question.strip()\n",
        "\n",
        "    if response_cleaned.lower().startswith(question_cleaned.lower()):\n",
        "        response_cleaned = response_cleaned[len(question_cleaned):].strip()\n",
        "\n",
        "    return response_cleaned\n",
        "\n",
        "for record in datasets[\"smolvlm\"]:\n",
        "    question = record.get(\"question\", \"\")\n",
        "    record[\"smolvlm_response\"] = clean_smolvlm_response(record.get(\"smolvlm_response\", \"\"), question)\n",
        "\n",
        "smolvlm_cleaned_path = os.path.join(dataset_folder, \"mini_gqa_with_smolvlm_cleaned.json\")\n",
        "with open(smolvlm_cleaned_path, \"w\") as f:\n",
        "    json.dump(datasets[\"smolvlm\"], f, indent=2)\n",
        "\n",
        "print(f\"Fully Cleaned SmolVLM dataset saved to: {smolvlm_cleaned_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jaHAhhCPZCA",
        "outputId": "b4e9c5ae-85b9-4277-c696-799ca9b9caec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fully Cleaned SmolVLM dataset saved to: /content/drive/MyDrive/mmml_project/outputs/mini_gqa_with_smolvlm_cleaned.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "datasets = {}\n",
        "for model, path in file_paths.items():\n",
        "    with open(path, \"r\") as f:\n",
        "        dataset_list = json.load(f)\n",
        "        datasets[model] = {entry[\"imageId\"]: entry for entry in dataset_list}\n",
        "\n",
        "def create_csv(strong_model, weak_model, output_filename):\n",
        "    matched_data = []\n",
        "\n",
        "    for image_id, strong_entry in datasets[strong_model].items():\n",
        "        weak_entry = datasets[weak_model].get(image_id)\n",
        "\n",
        "        if weak_entry and strong_entry[\"question\"] == weak_entry[\"question\"]:\n",
        "            matched_data.append({\n",
        "                \"imageId\": image_id,\n",
        "                \"image_file\": strong_entry[\"image_file\"],\n",
        "                \"question\": strong_entry[\"question\"],\n",
        "                \"answer\": strong_entry[\"answer\"],\n",
        "                \"full_answer\": strong_entry[\"fullAnswer\"],\n",
        "                \"strong_model_response\": strong_entry.get(f\"{strong_model}_response\", \"\"),\n",
        "                \"weak_model_response\": weak_entry.get(f\"{weak_model}_response\", \"\"),\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(matched_data)\n",
        "    csv_path = os.path.join(dataset_folder, output_filename)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved: {csv_path}\")\n",
        "\n",
        "create_csv(\"blip\", \"llava\", \"blip_vs_llava.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F6ph79gQHwU",
        "outputId": "27848528-aa76-4815-a5d2-097a1e439e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CSV saved: /content/drive/MyDrive/mmml_project/outputs/blip_vs_llava.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/mmml_project/outputs\"\n",
        "\n",
        "file_paths = {\n",
        "    \"gpt\": os.path.join(dataset_folder, \"mini_gqa_with_gpt.json\"),\n",
        "    \"smolvlm\": os.path.join(dataset_folder, \"mini_gqa_with_smolvlm.json\"),\n",
        "    \"blip\": os.path.join(dataset_folder, \"mini_gqa_with_blip.json\"),\n",
        "    \"llava\": os.path.join(dataset_folder, \"mini_gqa_with_llava.json\"),\n",
        "}\n",
        "\n",
        "for model, path in file_paths.items():\n",
        "    try:\n",
        "        with open(path, \"r\") as f:\n",
        "            json.load(f)\n",
        "        print(f\"{model} JSON is valid: {path}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error in {model} JSON file: {path}\")\n",
        "        print(f\"JSON Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81msstT4Snys",
        "outputId": "65ba5f97-ef78-4ec6-a308-146b82bb49af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt JSON is valid: /content/drive/MyDrive/mmml_project/outputs/mini_gqa_with_gpt.json\n",
            "smolvlm JSON is valid: /content/drive/MyDrive/mmml_project/outputs/mini_gqa_with_smolvlm.json\n",
            "blip JSON is valid: /content/drive/MyDrive/mmml_project/outputs/mini_gqa_with_blip.json\n",
            "llava JSON is valid: /content/drive/MyDrive/mmml_project/outputs/mini_gqa_with_llava.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9_u2Kr6hU4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}